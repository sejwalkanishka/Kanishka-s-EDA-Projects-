{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:11.539383Z",
     "iopub.status.busy": "2022-07-02T06:32:11.538976Z",
     "iopub.status.idle": "2022-07-02T06:32:11.559885Z",
     "shell.execute_reply": "2022-07-02T06:32:11.558929Z",
     "shell.execute_reply.started": "2022-07-02T06:32:11.539343Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "cfg = tf.compat.v1.ConfigProto()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:11.589197Z",
     "iopub.status.busy": "2022-07-02T06:32:11.58822Z",
     "iopub.status.idle": "2022-07-02T06:32:11.612481Z",
     "shell.execute_reply": "2022-07-02T06:32:11.611304Z",
     "shell.execute_reply.started": "2022-07-02T06:32:11.58915Z"
    }
   },
   "outputs": [],
   "source": [
    "hr_data = pd.read_csv('../input/hr-analytics/HR_comma_sep.csv', encoding  = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:11.669924Z",
     "iopub.status.busy": "2022-07-02T06:32:11.669486Z",
     "iopub.status.idle": "2022-07-02T06:32:11.685342Z",
     "shell.execute_reply": "2022-07-02T06:32:11.68451Z",
     "shell.execute_reply.started": "2022-07-02T06:32:11.669874Z"
    }
   },
   "outputs": [],
   "source": [
    "hr_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving target feature to the last for our easiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:11.758906Z",
     "iopub.status.busy": "2022-07-02T06:32:11.7582Z",
     "iopub.status.idle": "2022-07-02T06:32:11.766669Z",
     "shell.execute_reply": "2022-07-02T06:32:11.765816Z",
     "shell.execute_reply.started": "2022-07-02T06:32:11.758837Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = hr_data.columns.tolist()\n",
    "new_position = 10\n",
    "\n",
    "cols.insert(new_position, cols.pop(cols.index('left')))\n",
    "hr_data = hr_data[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the columns has sucessfully indexed to the last or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:11.814364Z",
     "iopub.status.busy": "2022-07-02T06:32:11.813746Z",
     "iopub.status.idle": "2022-07-02T06:32:11.830795Z",
     "shell.execute_reply": "2022-07-02T06:32:11.829286Z",
     "shell.execute_reply.started": "2022-07-02T06:32:11.814318Z"
    }
   },
   "outputs": [],
   "source": [
    "hr_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:11.858249Z",
     "iopub.status.busy": "2022-07-02T06:32:11.857471Z",
     "iopub.status.idle": "2022-07-02T06:32:11.875259Z",
     "shell.execute_reply": "2022-07-02T06:32:11.874387Z",
     "shell.execute_reply.started": "2022-07-02T06:32:11.85821Z"
    }
   },
   "outputs": [],
   "source": [
    "hr_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:11.910892Z",
     "iopub.status.busy": "2022-07-02T06:32:11.910111Z",
     "iopub.status.idle": "2022-07-02T06:32:11.950254Z",
     "shell.execute_reply": "2022-07-02T06:32:11.949369Z",
     "shell.execute_reply.started": "2022-07-02T06:32:11.910849Z"
    }
   },
   "outputs": [],
   "source": [
    "hr_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've 3 categorical columns (Department, Salary, eft). Hence we'll do a quick analysis to see how they impact our target variable (left).\n",
    "Firt of all, let's analyze employees according to their department for better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:11.955187Z",
     "iopub.status.busy": "2022-07-02T06:32:11.954859Z",
     "iopub.status.idle": "2022-07-02T06:32:11.978232Z",
     "shell.execute_reply": "2022-07-02T06:32:11.977133Z",
     "shell.execute_reply.started": "2022-07-02T06:32:11.955158Z"
    }
   },
   "outputs": [],
   "source": [
    "hr_data.groupby('Department').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets have a quick analysis or employees according to their salaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:12.002868Z",
     "iopub.status.busy": "2022-07-02T06:32:12.002481Z",
     "iopub.status.idle": "2022-07-02T06:32:12.022862Z",
     "shell.execute_reply": "2022-07-02T06:32:12.021819Z",
     "shell.execute_reply.started": "2022-07-02T06:32:12.002837Z"
    }
   },
   "outputs": [],
   "source": [
    "hr_data.groupby('salary').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll finally do a quick analysis of left column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:12.044081Z",
     "iopub.status.busy": "2022-07-02T06:32:12.043724Z",
     "iopub.status.idle": "2022-07-02T06:32:12.062094Z",
     "shell.execute_reply": "2022-07-02T06:32:12.060824Z",
     "shell.execute_reply.started": "2022-07-02T06:32:12.044052Z"
    }
   },
   "outputs": [],
   "source": [
    "hr_data.groupby('left').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:12.087658Z",
     "iopub.status.busy": "2022-07-02T06:32:12.086573Z",
     "iopub.status.idle": "2022-07-02T06:32:12.100596Z",
     "shell.execute_reply": "2022-07-02T06:32:12.099563Z",
     "shell.execute_reply.started": "2022-07-02T06:32:12.087618Z"
    }
   },
   "outputs": [],
   "source": [
    "hr_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:12.128152Z",
     "iopub.status.busy": "2022-07-02T06:32:12.127388Z",
     "iopub.status.idle": "2022-07-02T06:32:12.141599Z",
     "shell.execute_reply": "2022-07-02T06:32:12.140336Z",
     "shell.execute_reply.started": "2022-07-02T06:32:12.128111Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of duplicates : \", len(hr_data[hr_data.duplicated()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:12.169832Z",
     "iopub.status.busy": "2022-07-02T06:32:12.169414Z",
     "iopub.status.idle": "2022-07-02T06:32:12.189632Z",
     "shell.execute_reply": "2022-07-02T06:32:12.188752Z",
     "shell.execute_reply.started": "2022-07-02T06:32:12.169794Z"
    }
   },
   "outputs": [],
   "source": [
    "hr_data = hr_data.drop_duplicates()\n",
    "print(\"Number of duplicates : \", len(hr_data[hr_data.duplicated()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we'll check the distribution of data using countplot.\n",
    "Let's see the data distribution of our categorical columns in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:12.211941Z",
     "iopub.status.busy": "2022-07-02T06:32:12.210709Z",
     "iopub.status.idle": "2022-07-02T06:32:12.375734Z",
     "shell.execute_reply": "2022-07-02T06:32:12.374833Z",
     "shell.execute_reply.started": "2022-07-02T06:32:12.211884Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(hr_data.left, palette = \"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that column (left) don't have a normal distribution which can cause biasness in our ML model. Hence we'll standardized our data later in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:12.378788Z",
     "iopub.status.busy": "2022-07-02T06:32:12.378047Z",
     "iopub.status.idle": "2022-07-02T06:32:12.572421Z",
     "shell.execute_reply": "2022-07-02T06:32:12.570167Z",
     "shell.execute_reply.started": "2022-07-02T06:32:12.378741Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(x = 'salary' ,hue ='left' ,palette = \"Set2\" , data= hr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that employees with low and medium salary are more likely to leave the organization than employees with higher salaries. However, the first two bars show that there are more employees with low and medium salary than higher ones' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:12.574829Z",
     "iopub.status.busy": "2022-07-02T06:32:12.574069Z",
     "iopub.status.idle": "2022-07-02T06:32:12.828481Z",
     "shell.execute_reply": "2022-07-02T06:32:12.827185Z",
     "shell.execute_reply.started": "2022-07-02T06:32:12.574784Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 7))\n",
    "sns.countplot(x = 'Department' ,hue ='left' ,palette = \"Set2\" , data= hr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The points observed are mentioned below:\n",
    "* The distribution of data is almost normal as we can see.\n",
    "* This tells that employees working in the sales department are more than any other department.\n",
    "* The employees working in management department are less than any other department.\n",
    "* Most employees left are from sales department.\n",
    "* The department with least number of employees leaving is management.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:12.832322Z",
     "iopub.status.busy": "2022-07-02T06:32:12.83165Z",
     "iopub.status.idle": "2022-07-02T06:32:52.021676Z",
     "shell.execute_reply": "2022-07-02T06:32:52.020749Z",
     "shell.execute_reply.started": "2022-07-02T06:32:12.832265Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(hr_data, hue = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pairplot tells us the story of the data. I've listed some points below regardind the employees of left:\n",
    "* The poeple who left the organization had a satisfication level less than 0.4\n",
    "* The number of projects done by employees who left were 2 or less than 2.\n",
    "* The average monthly hours spent by those employees who left were 150 and below it. Seems they weren't that     much intrested due to some reasons. \n",
    "* The time spent by these employees who left was 3 months and below it. \n",
    "* The employees that have promtional value greater than 0.3 are more likely to stay in company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:52.023862Z",
     "iopub.status.busy": "2022-07-02T06:32:52.023006Z",
     "iopub.status.idle": "2022-07-02T06:32:52.629184Z",
     "shell.execute_reply": "2022-07-02T06:32:52.628032Z",
     "shell.execute_reply.started": "2022-07-02T06:32:52.023826Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13, 7))\n",
    "sns.heatmap(hr_data.corr(), annot = True, cmap = 'Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I've plotted a heatmap above that shows the relationships between two variables based on values and colors.\n",
    "* The factor that most influence the decision of an employee whether they will stay in a company or not is time   spend at company\n",
    "* Satisfication level also does not seems to have a good relation with column (left)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing is the most important part of a machine learning model building. A ML algo only understand the data in numerical format and it should be standardized or normalized. \n",
    "First of all, let's encode the data by creating dummies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:52.631374Z",
     "iopub.status.busy": "2022-07-02T06:32:52.630662Z",
     "iopub.status.idle": "2022-07-02T06:32:52.642033Z",
     "shell.execute_reply": "2022-07-02T06:32:52.640999Z",
     "shell.execute_reply.started": "2022-07-02T06:32:52.631338Z"
    }
   },
   "outputs": [],
   "source": [
    "hr_data = pd.get_dummies(hr_data, columns=['salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll do feature selection here for training and testing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:52.644369Z",
     "iopub.status.busy": "2022-07-02T06:32:52.643169Z",
     "iopub.status.idle": "2022-07-02T06:32:52.653808Z",
     "shell.execute_reply": "2022-07-02T06:32:52.652896Z",
     "shell.execute_reply.started": "2022-07-02T06:32:52.644228Z"
    }
   },
   "outputs": [],
   "source": [
    "X = hr_data.drop(columns = ['left', 'Department', 'Work_accident'])\n",
    "y = hr_data['left']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's essential to standardized our data like we said earlier if we want a really good machine learning algorithm that can perform well on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:52.655723Z",
     "iopub.status.busy": "2022-07-02T06:32:52.655189Z",
     "iopub.status.idle": "2022-07-02T06:32:52.670937Z",
     "shell.execute_reply": "2022-07-02T06:32:52.669749Z",
     "shell.execute_reply.started": "2022-07-02T06:32:52.655682Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our data is standardized and both encoded now, we'll move towards training our data and then testing it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:52.672987Z",
     "iopub.status.busy": "2022-07-02T06:32:52.672379Z",
     "iopub.status.idle": "2022-07-02T06:32:52.680382Z",
     "shell.execute_reply": "2022-07-02T06:32:52.679482Z",
     "shell.execute_reply.started": "2022-07-02T06:32:52.672955Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll choose 3 machine learning models for my data, Logistic Regression, Decison Tree and Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:52.684399Z",
     "iopub.status.busy": "2022-07-02T06:32:52.683841Z",
     "iopub.status.idle": "2022-07-02T06:32:53.611127Z",
     "shell.execute_reply": "2022-07-02T06:32:53.610032Z",
     "shell.execute_reply.started": "2022-07-02T06:32:52.684365Z"
    }
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    '        Logistic Regression': LogisticRegression(),\n",
    "    '        Decision Tree': DecisionTreeClassifier(),\n",
    "    '        Random Forest Classifier': RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "\n",
    "accuracy, precision, recall = {}, {}, {}\n",
    "\n",
    "for i in models.keys():\n",
    "    \n",
    "    models[i].fit(X_train, y_train)\n",
    "    y_pred = models[i].predict(X_test)\n",
    "    \n",
    "    accuracy[i] = accuracy_score(y_pred, y_test)\n",
    "    precision[i] = precision_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see which our model performs the best here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:53.61276Z",
     "iopub.status.busy": "2022-07-02T06:32:53.612425Z",
     "iopub.status.idle": "2022-07-02T06:32:53.627333Z",
     "shell.execute_reply": "2022-07-02T06:32:53.626182Z",
     "shell.execute_reply.started": "2022-07-02T06:32:53.61273Z"
    }
   },
   "outputs": [],
   "source": [
    "hr_data_models = pd.DataFrame(index=models.keys(), columns=['Accuracy', 'Precision'])\n",
    "hr_data_models['Accuracy'] = accuracy.values()\n",
    "hr_data_models['Precision'] = precision.values()\n",
    "hr_data_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:53.628982Z",
     "iopub.status.busy": "2022-07-02T06:32:53.628652Z",
     "iopub.status.idle": "2022-07-02T06:32:53.855163Z",
     "shell.execute_reply": "2022-07-02T06:32:53.853962Z",
     "shell.execute_reply.started": "2022-07-02T06:32:53.628953Z"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "conf_mat = pd.DataFrame(data = cm, columns = ['Predicted Not Left', 'Predicted Left'], index = ['Actual Not Left', 'Actual Left'])\n",
    "sns.heatmap(conf_mat, annot = True, fmt='d', cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:37:16.069119Z",
     "iopub.status.busy": "2022-07-02T06:37:16.068672Z",
     "iopub.status.idle": "2022-07-02T06:37:16.0806Z",
     "shell.execute_reply": "2022-07-02T06:37:16.079299Z",
     "shell.execute_reply.started": "2022-07-02T06:37:16.069082Z"
    }
   },
   "outputs": [],
   "source": [
    "TN=cm[0,0]\n",
    "TP=cm[1,1]\n",
    "FN=cm[1,0]\n",
    "FP=cm[0,1]\n",
    "sensitivity=TP/float(TP+FN)\n",
    "specificity=TN/float(TN+FP)\n",
    "print('The acuuracy of the model = TP+TN/(TP+TN+FP+FN) = ',(TP+TN)/float(TP+TN+FP+FN),'\\n', '\\n',\n",
    "        'Sensitivity or True Positive Rate = TP/(TP+FN) = ',TP/float(TP+FN),'\\n',\n",
    "        'Specificity or True Negative Rate = TN/(TN+FP) = ',TN/float(TN+FP),'\\n', '\\n',\n",
    "        'Positive Predictive value = TP/(TP+FP) = ',TP/float(TP+FP),'\\n',\n",
    "        'Negative predictive Value = TN/(TN+FN) = ',TN/float(TN+FN),'\\n',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've used Multilayer perceptron and Artifical Neural Network here in this notebook, Let's train them and see their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:32:53.870445Z",
     "iopub.status.busy": "2022-07-02T06:32:53.869214Z",
     "iopub.status.idle": "2022-07-02T06:33:21.071019Z",
     "shell.execute_reply": "2022-07-02T06:33:21.069582Z",
     "shell.execute_reply.started": "2022-07-02T06:32:53.870401Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter = 500)\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp_y_pred = mlp.predict(X_test)\n",
    "\n",
    "print('The accuracy score of MLP is : ', accuracy_score(mlp_y_pred, y_test))\n",
    "print('The precision score of MLP is : ', precision_score(mlp_y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T06:33:21.078692Z",
     "iopub.status.busy": "2022-07-02T06:33:21.077508Z",
     "iopub.status.idle": "2022-07-02T06:33:26.626781Z",
     "shell.execute_reply": "2022-07-02T06:33:26.625728Z",
     "shell.execute_reply.started": "2022-07-02T06:33:21.078623Z"
    }
   },
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=6,activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=6,activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "ann.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "ann.fit(X_train,y_train,batch_size=32,epochs=10)\n",
    "ann_y_pred = ann.predict(X_test)\n",
    "ann_y_pred = (ann_y_pred>0.5)\n",
    "\n",
    "print('The accuracy score of MLP is : ', accuracy_score(y_test, ann_y_pred))\n",
    "print('The precision score of MLP is : ', precision_score(y_test, ann_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we did some emploratory data analysis of our dataset and then we did some cleaning. Later we did some preprocessing and then trained 3 Lachine Learning algorithms and then 2 Neural Networks. The results showed that **Random Forest Classifier** has outperformed all of the models with 98 percent accuray and the model that performed very bad was logistic regression. "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 11142,
     "sourceId": 15488,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30203,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
